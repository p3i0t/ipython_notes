{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM (Long-Short Term Memory)\n",
    "LSTM is a special variant of recurrent neural network(RNN), which provide a solution for the\n",
    "exploding and vanishing gradient problem. It performs unreasonably well on many\n",
    "works due to its structure flexibility and the notion of order in time,\n",
    "like translation (many inputs to many outputs), classfication (many inputs to one outputs)\n",
    "and so on.\n",
    "## LSTM logic\n",
    "\n",
    "## LSTM with torch\n",
    "All the snippets below are implemented in torch7, which is one of the powerful open\n",
    "source library for neural network.\n",
    "### LSTM cell in a plain way\n",
    "\n",
    "```lua\n",
    "require 'nn'\n",
    "require 'nngraph'\n",
    "\n",
    "-- There are three gates in one sigle LSTM cell, which are input, forget,\n",
    "-- output gate respectively.\n",
    "------------------------------------\n",
    "-- Define the inputs and dimension of the linear module\n",
    "------------------------------------\n",
    "ninputs = 4; noutputs = 4\n",
    "x = nn.Identity()()\n",
    "h = nn.Identity()()\n",
    "c = nn.Identity()()\n",
    "\n",
    "function input_linear_sum(x, h)\n",
    "    return nn.CAddTable()({\n",
    "        nn.Linear(ninputs,noutputs)(x),\n",
    "        nn.Linear(ninputs,noutputs)(h)\n",
    "        })\n",
    "end\n",
    "-- Define the input gate\n",
    "input_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "-- Define the forget gate\n",
    "forget_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "-- Define the output gate\n",
    "output_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "-- Define the cell state\n",
    "c_in  = nn.Tanh()(new input_linear_sum(x,h))\n",
    "-- Update cell state\n",
    "c_new = nn.CAddTable()({\n",
    "    nn.CMulTable()({forget_gate,c}),\n",
    "    nn.CMulTable()({input_gate, c_in})\n",
    "    })\n",
    "-- Compute output\n",
    "h_new = nn.CMulTable()({output_gate, nn.Tanh()(c_new)})\n",
    "-- Define the model graph\n",
    "lstm_model = nn.gModule({x,h,c},{h_new,c_new})\n",
    "```\n",
    "\n",
    "### LSTM cell in a neat way\n",
    "Wrap all the variables of a LSTM cell in a function.\n",
    "\n",
    "```lua\n",
    "require 'nn'\n",
    "require 'nngraph'\n",
    "\n",
    "--------------------------------------\n",
    "-- Define LSTM cell in one function\n",
    "--------------------------------------\n",
    "function lstm(x,h,c)\n",
    "\tfunction input_linear_sum(x,h)\n",
    "\t\treturn nn.CAddTable()({\n",
    "            nn.Linear(ninputs,noutputs)(x),\n",
    "            nn.Linear(ninputs,noutputs)(h)\n",
    "            })\n",
    "\tend\n",
    "\t-- Define 3 gates (input, output, forget)\n",
    "\tlocal input_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "\tlocal output_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "\tlocal forget_gate = nn.Sigmoid()(new input_linear_sum(x,h))\n",
    "\t-- Squash (transform) the input with tanh\n",
    "\tlocal c_in  = nn.Tanh()(new input_linear_sum(x,h))\n",
    "\tlocal c_new = nn.CAddTable()({\n",
    "\t\t\tnn.CMulTable()({forget_gate,c}),\n",
    "\t\t\tnn.CMulTable()({input_gate, c_in})\n",
    "\t\t\t})\n",
    "\tlocal h_new = nn.CMulTable()({output_gate,nn.Tanh()(c_new)})\n",
    "\t-- Return new h and c\n",
    "\treturn c_new, h_new\n",
    "end\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
